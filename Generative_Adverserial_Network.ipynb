{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## DEEP CONVOLUTIONAL GENERATIVE ADVERSERIAL NETWORK\n",
    "\n",
    "#### The Discriminator and Generator\n",
    "\n",
    "The purpose of the generator in a GAN is to learn to generate synthetic data that resembles real data samples. It does so by transforming the random noise vectors into meaningful output data, such as images. Through the adversarial training process, where it competes against the discriminator, the generator learns to produce outputs that are indistinguishable from real data to the discriminator.\n",
    "\n",
    "The discriminator, on the other hand, is responsible for distinguishing between real and fake data samples. It receives both real and fake data samples as input during training and learns to differentiate between them.\n",
    "\n",
    "By training the generator to fool the discriminator into classifying its generated samples as real, the generator indirectly learns the distribution of real data. However, it does so without explicitly seeing real data samples during training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "2efGTzDoaRE9",
    "ExecuteTime": {
     "end_time": "2024-02-29T15:15:45.216603200Z",
     "start_time": "2024-02-29T15:15:45.200380300Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import (\n",
    "    layers,\n",
    "    models,\n",
    "    callbacks,\n",
    "    losses,\n",
    "    utils,\n",
    "    metrics,\n",
    "    optimizers,\n",
    "    backend\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from IPython import display\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import OrderedDict, namedtuple\n",
    "from itertools import product\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Parameters"
   ],
   "metadata": {
    "id": "D_kE85W16no6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "IMAGE_SIZE = 64\n",
    "CHANNELS = 1\n",
    "BATCH_SIZE = 128\n",
    "Z_DIM = 100\n",
    "EPOCHS = 100\n",
    "LOAD_MODEL = True\n",
    "ADAM_BETA_1 = 0.5\n",
    "ADAM_BETA_2 = 0.999\n",
    "LEARNING_RATE = 0.0002\n",
    "DROPOUT_P = 0.25\n",
    "NOISE_PARAM = 0.1"
   ],
   "metadata": {
    "id": "dL7h0RgW6is5",
    "ExecuteTime": {
     "end_time": "2024-02-29T14:09:20.435093500Z",
     "start_time": "2024-02-29T14:09:20.421175100Z"
    }
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46384 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = utils.image_dataset_from_directory(\n",
    "    \"C:/Users/jorda/Documents/GenDL_datasets/lego_bricks_dl_dataset\",\n",
    "    labels = None,\n",
    "    color_mode = \"grayscale\",\n",
    "    image_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    seed = 42,\n",
    "    interpolation = \"bilinear\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T14:09:25.166795800Z",
     "start_time": "2024-02-29T14:09:20.748823500Z"
    }
   },
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    \"\"\"Scales the data to be between [-1, 1] range.\"\"\"\n",
    "    img = (tf.cast(img, \"float32\") - 127.5) / 127.5\n",
    "    return img\n",
    "\n",
    "train = train_data.map(lambda x: preprocess(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T14:09:25.214628900Z",
     "start_time": "2024-02-29T14:09:25.168983600Z"
    }
   },
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Model Architecture"
   ],
   "metadata": {
    "id": "QOf0roqD8EP8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "### The discriminator\n",
    "discriminator = tf.keras.Sequential([\n",
    "    layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS)),\n",
    "    layers.Conv2D(filters = 64, kernel_size = 4, strides = 2, padding = \"same\", use_bias = False, name=\"Conv2D_1\"),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Conv2D(filters = 128, kernel_size = 4, strides = 2, padding = \"same\", use_bias = False),\n",
    "    layers.BatchNormalization(momentum = 0.9),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Conv2D(filters = 256, kernel_size = 4, strides = 2, padding = \"same\", use_bias = False),\n",
    "    layers.BatchNormalization(momentum = 0.9),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Conv2D(filters = 512, kernel_size = 4, strides = 2, padding=\"same\", use_bias = False),\n",
    "    layers.BatchNormalization(momentum = 0.9),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Conv2D(filters = 1, \n",
    "                  kernel_size = 4, \n",
    "                  strides = 1, \n",
    "                  padding = \"valid\", \n",
    "                  use_bias = False, \n",
    "                  activation = 'sigmoid'),\n",
    "    layers.Flatten()\n",
    "])\n",
    "\n",
    "discriminator.summary()"
   ],
   "metadata": {
    "id": "WecGAq-l8GB8",
    "ExecuteTime": {
     "end_time": "2024-02-29T14:09:25.357346300Z",
     "start_time": "2024-02-29T14:09:25.215705600Z"
    }
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv2D_1 (Conv2D)           (None, 32, 32, 64)        1024      \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 128)       131072    \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 16, 16, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 8, 8, 256)         524288    \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 8, 8, 256)         1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 4, 4, 512)         2097152   \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 4, 4, 512)         2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 1, 1, 1)           8192      \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2765312 (10.55 MB)\n",
      "Trainable params: 2763520 (10.54 MB)\n",
      "Non-trainable params: 1792 (7.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_2 (Reshape)         (None, 1, 1, 100)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_10 (Conv2  (None, 4, 4, 512)         819200    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 4, 4, 512)         2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_11 (Conv2  (None, 8, 8, 256)         2097152   \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 8, 8, 256)         1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_12 (Conv2  (None, 16, 16, 128)       524288    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 16, 16, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_13 (Conv2  (None, 32, 32, 64)        131072    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 32, 32, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_14 (Conv2  (None, 64, 64, 1)         1024      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3576576 (13.64 MB)\n",
      "Trainable params: 3574656 (13.64 MB)\n",
      "Non-trainable params: 1920 (7.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### The generator\n",
    "generator = tf.keras.Sequential([\n",
    "    layers.Input(shape=(100, 1)),\n",
    "    layers.Reshape((1, 1, 100)),\n",
    "    layers.Conv2DTranspose(512, kernel_size=4, strides=1, padding=\"valid\", use_bias = False),\n",
    "    layers.BatchNormalization(momentum=0.9),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\", use_bias = False),\n",
    "    layers.BatchNormalization(momentum=0.9),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\", use_bias = False),\n",
    "    layers.BatchNormalization(momentum=0.9),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\", use_bias = False),\n",
    "    layers.BatchNormalization(momentum=0.9),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Conv2DTranspose(\n",
    "        1,\n",
    "        kernel_size=4,\n",
    "        strides=2,\n",
    "        padding=\"same\",\n",
    "        use_bias = False,\n",
    "        activation = 'tanh'\n",
    "    )\n",
    "])\n",
    "\n",
    "generator.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T14:09:25.530559400Z",
     "start_time": "2024-02-29T14:09:25.379344700Z"
    }
   },
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Compiling the GAN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DCGAN(models.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer):\n",
    "        super(DCGAN, self).compile()\n",
    "        self.loss_fn = losses.BinaryCrossentropy()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_metric = metrics.Mean(name=\"d_loss\")\n",
    "        self.d_real_acc_metric = metrics.BinaryAccuracy(name=\"d_real_acc\")\n",
    "        self.d_fake_acc_metric = metrics.BinaryAccuracy(name=\"d_fake_acc\")\n",
    "        self.d_acc_metric = metrics.BinaryAccuracy(name=\"d_acc\")\n",
    "        self.g_loss_metric = metrics.Mean(name=\"g_loss\")\n",
    "        self.g_acc_metric = metrics.BinaryAccuracy(name=\"g_acc\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.d_loss_metric,\n",
    "            self.d_real_acc_metric,\n",
    "            self.d_fake_acc_metric,\n",
    "            self.d_acc_metric,\n",
    "            self.g_loss_metric,\n",
    "            self.g_acc_metric,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(batch_size, self.latent_dim)\n",
    "        )\n",
    "\n",
    "        # Train the discriminator on fake images\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_images = self.generator(\n",
    "                random_latent_vectors, training=True\n",
    "            )\n",
    "            real_predictions = self.discriminator(real_images, training=True)\n",
    "            fake_predictions = self.discriminator(\n",
    "                generated_images, training=True\n",
    "            )\n",
    "\n",
    "            real_labels = tf.ones_like(real_predictions)\n",
    "            real_noisy_labels = real_labels + NOISE_PARAM * tf.random.uniform(\n",
    "                tf.shape(real_predictions)\n",
    "            )\n",
    "            fake_labels = tf.zeros_like(fake_predictions)\n",
    "            fake_noisy_labels = fake_labels - NOISE_PARAM * tf.random.uniform(\n",
    "                tf.shape(fake_predictions)\n",
    "            )\n",
    "\n",
    "            d_real_loss = self.loss_fn(real_noisy_labels, real_predictions)\n",
    "            d_fake_loss = self.loss_fn(fake_noisy_labels, fake_predictions)\n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2.0\n",
    "\n",
    "            g_loss = self.loss_fn(real_labels, fake_predictions)\n",
    "\n",
    "        gradients_of_discriminator = disc_tape.gradient(\n",
    "            d_loss, self.discriminator.trainable_variables\n",
    "        )\n",
    "        gradients_of_generator = gen_tape.gradient(\n",
    "            g_loss, self.generator.trainable_variables\n",
    "        )\n",
    "\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(gradients_of_discriminator, discriminator.trainable_variables)\n",
    "        )\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gradients_of_generator, generator.trainable_variables)\n",
    "        )\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.d_real_acc_metric.update_state(real_labels, real_predictions)\n",
    "        self.d_fake_acc_metric.update_state(fake_labels, fake_predictions)\n",
    "        self.d_acc_metric.update_state(\n",
    "            [real_labels, fake_labels], [real_predictions, fake_predictions]\n",
    "        )\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        self.g_acc_metric.update_state(real_labels, fake_predictions)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T15:23:14.972741400Z",
     "start_time": "2024-02-29T15:23:14.950867500Z"
    }
   },
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a DCGAN\n",
    "dcgan = DCGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=100\n",
    ")"
   ],
   "metadata": {
    "id": "VJd72le_OkTO",
    "ExecuteTime": {
     "end_time": "2024-02-29T15:23:15.277015200Z",
     "start_time": "2024-02-29T15:23:15.250013500Z"
    }
   },
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Crucial checkpointing\n",
    "Checkpointing allows me to save a model's weights during training. I can set the checkpoint at the end of an epoch and if the training process is long, I can just save at a checkpoint and resume training from there at a later time. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    dcgan.load_weights(\"checkpoint/checkpoint.ckpt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T15:23:16.307186200Z",
     "start_time": "2024-02-29T15:23:16.244302300Z"
    }
   },
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Training the GAN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Compile it with the two optimizers and their user-defined parameters\n",
    "dcgan.compile(\n",
    "    d_optimizer=optimizers.Adam(\n",
    "        learning_rate=0.0002, beta_1 = 0.5, beta_2 = 0.999\n",
    "    ),\n",
    "    g_optimizer=optimizers.Adam(\n",
    "        learning_rate=0.0002, beta_1 = 0.5, beta_2 = 0.999\n",
    "    ),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T15:23:18.221098Z",
     "start_time": "2024-02-29T15:23:18.153961400Z"
    }
   },
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a model save checkpoint\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=\"checkpoint/checkpoint.ckpt\",\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "class ImageGenerator(callbacks.Callback):\n",
    "    def __init__(self, num_img, latent_dim):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "\n",
    "    @staticmethod\n",
    "    def save_image(image, path):\n",
    "        # Convert the image from NumPy array to PIL Image\n",
    "        image = Image.fromarray(image.astype('uint8'))\n",
    "        # Save the image\n",
    "        image.save(path)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get('loss') is not None:\n",
    "            print(f\"Train Loss: {logs.get('loss')}\")\n",
    "        if logs.get(\"accuracy\") is not None:\n",
    "            print(f\"Train Accuracy: {logs.get('accuracy')}\")\n",
    "        if logs.get(\"val_loss\") is not None:\n",
    "            print(f\"Validation Loss: {logs.get('val_loss')}\")\n",
    "        if logs.get(\"val_accuracy\") is not None:\n",
    "            print(f\"Validation Accuracy: {logs.get('val_accuracy')}\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(self.num_img, self.latent_dim)\n",
    "        )\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images = generated_images * 127.5 + 127.5\n",
    "        generated_images = generated_images.numpy()\n",
    "        self.save_image(generated_images, f\"./output/generated_img_{epoch}03d.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T15:23:18.723243900Z",
     "start_time": "2024-02-29T15:23:18.717720400Z"
    }
   },
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[62], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mdcgan\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_checkpoint_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtensorboard_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m        \u001B[49m\u001B[43mImageGenerator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_img\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlatent_dim\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mZ_DIM\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1734\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1735\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1736\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1739\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1740\u001B[0m ):\n\u001B[0;32m   1741\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1742\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1743\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1744\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    822\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 825\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    827\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    828\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:890\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    886\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# Fall through to cond-based initialization.\u001B[39;00m\n\u001B[0;32m    887\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    888\u001B[0m     \u001B[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001B[39;00m\n\u001B[0;32m    889\u001B[0m     \u001B[38;5;66;03m# no_variable_creation function.\u001B[39;00m\n\u001B[1;32m--> 890\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    891\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    892\u001B[0m   _, _, filtered_flat_args \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    893\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn\u001B[38;5;241m.\u001B[39m_function_spec  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    894\u001B[0m       \u001B[38;5;241m.\u001B[39mcanonicalize_function_inputs(\n\u001B[0;32m    895\u001B[0m           args, kwds))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:147\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001B[39;00m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    146\u001B[0m   (concrete_function,\n\u001B[1;32m--> 147\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m concrete_function\u001B[38;5;241m.\u001B[39m_call_flat(\n\u001B[0;32m    149\u001B[0m     filtered_flat_args, captured_inputs\u001B[38;5;241m=\u001B[39mconcrete_function\u001B[38;5;241m.\u001B[39mcaptured_inputs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:398\u001B[0m, in \u001B[0;36mTracingCompiler._maybe_define_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m    395\u001B[0m args \u001B[38;5;241m=\u001B[39m placeholder_bound_args\u001B[38;5;241m.\u001B[39margs\n\u001B[0;32m    396\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m placeholder_bound_args\u001B[38;5;241m.\u001B[39mkwargs\n\u001B[1;32m--> 398\u001B[0m concrete_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_concrete_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    399\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    401\u001B[0m \u001B[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001B[39;00m\n\u001B[0;32m    402\u001B[0m graph_capture_container \u001B[38;5;241m=\u001B[39m concrete_function\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mfunction_captures\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:305\u001B[0m, in \u001B[0;36mTracingCompiler._create_concrete_function\u001B[1;34m(self, args, kwargs, func_graph)\u001B[0m\n\u001B[0;32m    301\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    302\u001B[0m   arg_names \u001B[38;5;241m=\u001B[39m base_arg_names\n\u001B[0;32m    304\u001B[0m concrete_function \u001B[38;5;241m=\u001B[39m monomorphic_function\u001B[38;5;241m.\u001B[39mConcreteFunction(\n\u001B[1;32m--> 305\u001B[0m     \u001B[43mfunc_graph_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    306\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    307\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_python_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    308\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    309\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    310\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marg_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapture_by_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_capture_by_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcreate_placeholders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m,\n\u001B[0;32m    315\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_attributes,\n\u001B[0;32m    316\u001B[0m     spec\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_spec,\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[39;00m\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001B[39;00m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001B[39;00m\n\u001B[0;32m    320\u001B[0m     \u001B[38;5;66;03m# ConcreteFunction.\u001B[39;00m\n\u001B[0;32m    321\u001B[0m     shared_func_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    322\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m concrete_function\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1055\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func\u001B[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001B[0m\n\u001B[0;32m   1052\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[0;32m   1054\u001B[0m _, original_func \u001B[38;5;241m=\u001B[39m tf_decorator\u001B[38;5;241m.\u001B[39munwrap(python_func)\n\u001B[1;32m-> 1055\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mpython_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfunc_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfunc_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1057\u001B[0m \u001B[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[39;00m\n\u001B[0;32m   1058\u001B[0m \u001B[38;5;66;03m# TensorArrays and `None`s.\u001B[39;00m\n\u001B[0;32m   1059\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m variable_utils\u001B[38;5;241m.\u001B[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:597\u001B[0m, in \u001B[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m    593\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m default_graph\u001B[38;5;241m.\u001B[39m_variable_creator_scope(scope, priority\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m):  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    594\u001B[0m   \u001B[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[39;00m\n\u001B[0;32m    595\u001B[0m   \u001B[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001B[39;00m\n\u001B[0;32m    596\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(compile_with_xla):\n\u001B[1;32m--> 597\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mweak_wrapped_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__wrapped__\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    598\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:41\u001B[0m, in \u001B[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 41\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[43m      \u001B[49m\u001B[43moriginal_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     43\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[43m      \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[43m      \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mConversionOptions\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[43m          \u001B[49m\u001B[43mrecursive\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[43m          \u001B[49m\u001B[43moptional_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mautograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[43m          \u001B[49m\u001B[43muser_requested\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     49\u001B[0m \u001B[43m      \u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m     51\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001B[0m, in \u001B[0;36mconverted_call\u001B[1;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    438\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 439\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mconverted_f\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43meffective_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    440\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    441\u001B[0m     result \u001B[38;5;241m=\u001B[39m converted_f(\u001B[38;5;241m*\u001B[39meffective_args)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileht0381_e.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m \u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep_function\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfscope\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001B[0m, in \u001B[0;36mconverted_call\u001B[1;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_in_allowlist_cache(f, options):\n\u001B[0;32m    330\u001B[0m   logging\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllowlisted \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: from cache\u001B[39m\u001B[38;5;124m'\u001B[39m, f)\n\u001B[1;32m--> 331\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ag_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx()\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m ag_ctx\u001B[38;5;241m.\u001B[39mStatus\u001B[38;5;241m.\u001B[39mDISABLED:\n\u001B[0;32m    334\u001B[0m   logging\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllowlisted: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: AutoGraph is disabled in context\u001B[39m\u001B[38;5;124m'\u001B[39m, f)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:460\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[1;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[0;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 460\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\keras\\src\\engine\\training.py:1322\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.step_function\u001B[1;34m(model, iterator)\u001B[0m\n\u001B[0;32m   1318\u001B[0m     run_step \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mfunction(\n\u001B[0;32m   1319\u001B[0m         run_step, jit_compile\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, reduce_retracing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1320\u001B[0m     )\n\u001B[0;32m   1321\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(iterator)\n\u001B[1;32m-> 1322\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute_strategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1323\u001B[0m outputs \u001B[38;5;241m=\u001B[39m reduce_per_replica(\n\u001B[0;32m   1324\u001B[0m     outputs,\n\u001B[0;32m   1325\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_strategy,\n\u001B[0;32m   1326\u001B[0m     reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_reduction_method,\n\u001B[0;32m   1327\u001B[0m )\n\u001B[0;32m   1328\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1673\u001B[0m, in \u001B[0;36mStrategyBase.run\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m   1668\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscope():\n\u001B[0;32m   1669\u001B[0m   \u001B[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001B[39;00m\n\u001B[0;32m   1670\u001B[0m   \u001B[38;5;66;03m# applied when the caller is also in Eager mode.\u001B[39;00m\n\u001B[0;32m   1671\u001B[0m   fn \u001B[38;5;241m=\u001B[39m autograph\u001B[38;5;241m.\u001B[39mtf_convert(\n\u001B[0;32m   1672\u001B[0m       fn, autograph_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx(), convert_by_default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m-> 1673\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_extended\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_for_each_replica\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3250\u001B[0m, in \u001B[0;36mStrategyExtendedV1.call_for_each_replica\u001B[1;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[0;32m   3248\u001B[0m   kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m   3249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy()\u001B[38;5;241m.\u001B[39mscope():\n\u001B[1;32m-> 3250\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_for_each_replica\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4048\u001B[0m, in \u001B[0;36m_DefaultDistributionExtended._call_for_each_replica\u001B[1;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[0;32m   4046\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call_for_each_replica\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn, args, kwargs):\n\u001B[0;32m   4047\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ReplicaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy(), replica_id_in_sync_group\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m-> 4048\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    688\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    689\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[1;32m--> 690\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    691\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m    692\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001B[0m, in \u001B[0;36mconverted_call\u001B[1;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[0;32m    374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options)\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39muser_requested \u001B[38;5;129;01mand\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_allowlisted(f):\n\u001B[1;32m--> 377\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001B[39;00m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001B[39;00m\n\u001B[0;32m    381\u001B[0m \u001B[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001B[39;00m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;66;03m# things like builtins.\u001B[39;00m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39minternal_convert_user_code:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[1;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[0;32m    456\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mcall(args, kwargs)\n\u001B[0;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\keras\\src\\engine\\training.py:1303\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m   1302\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_step\u001B[39m(data):\n\u001B[1;32m-> 1303\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1304\u001B[0m     \u001B[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001B[39;00m\n\u001B[0;32m   1305\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "Cell \u001B[1;32mIn[57], line 70\u001B[0m, in \u001B[0;36mDCGAN.train_step\u001B[1;34m(self, real_images)\u001B[0m\n\u001B[0;32m     63\u001B[0m gradients_of_discriminator \u001B[38;5;241m=\u001B[39m disc_tape\u001B[38;5;241m.\u001B[39mgradient(\n\u001B[0;32m     64\u001B[0m     d_loss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdiscriminator\u001B[38;5;241m.\u001B[39mtrainable_variables\n\u001B[0;32m     65\u001B[0m )\n\u001B[0;32m     66\u001B[0m gradients_of_generator \u001B[38;5;241m=\u001B[39m gen_tape\u001B[38;5;241m.\u001B[39mgradient(\n\u001B[0;32m     67\u001B[0m     g_loss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerator\u001B[38;5;241m.\u001B[39mtrainable_variables\n\u001B[0;32m     68\u001B[0m )\n\u001B[1;32m---> 70\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43md_optimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_gradients\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mgradients_of_discriminator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdiscriminator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainable_variables\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mg_optimizer\u001B[38;5;241m.\u001B[39mapply_gradients(\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28mzip\u001B[39m(gradients_of_generator, generator\u001B[38;5;241m.\u001B[39mtrainable_variables)\n\u001B[0;32m     75\u001B[0m )\n\u001B[0;32m     77\u001B[0m \u001B[38;5;66;03m# Update metrics\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1230\u001B[0m, in \u001B[0;36mOptimizer.apply_gradients\u001B[1;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001B[0m\n\u001B[0;32m   1228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m skip_gradients_aggregation \u001B[38;5;129;01mand\u001B[39;00m experimental_aggregate_gradients:\n\u001B[0;32m   1229\u001B[0m     grads_and_vars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maggregate_gradients(grads_and_vars)\n\u001B[1;32m-> 1230\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_gradients\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrads_and_vars\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:652\u001B[0m, in \u001B[0;36m_BaseOptimizer.apply_gradients\u001B[1;34m(self, grads_and_vars, name)\u001B[0m\n\u001B[0;32m    650\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_weight_decay(trainable_variables)\n\u001B[0;32m    651\u001B[0m grads_and_vars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(grads, trainable_variables))\n\u001B[1;32m--> 652\u001B[0m iteration \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_internal_apply_gradients\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrads_and_vars\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    654\u001B[0m \u001B[38;5;66;03m# Apply variable constraints after applying gradients.\u001B[39;00m\n\u001B[0;32m    655\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m variable \u001B[38;5;129;01min\u001B[39;00m trainable_variables:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1260\u001B[0m, in \u001B[0;36mOptimizer._internal_apply_gradients\u001B[1;34m(self, grads_and_vars)\u001B[0m\n\u001B[0;32m   1256\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mesh \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_with_dtensor:\n\u001B[0;32m   1257\u001B[0m     \u001B[38;5;66;03m# Skip any usage of strategy logic for DTensor\u001B[39;00m\n\u001B[0;32m   1258\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m_internal_apply_gradients(grads_and_vars)\n\u001B[1;32m-> 1260\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__internal__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaybe_merge_call\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1261\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_distributed_apply_gradients_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1262\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_distribution_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrads_and_vars\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1264\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\distribute\\merge_call_interim.py:51\u001B[0m, in \u001B[0;36mmaybe_merge_call\u001B[1;34m(fn, strategy, *args, **kwargs)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \n\u001B[0;32m     33\u001B[0m \u001B[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;124;03m  The return value of the `fn` call.\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m strategy_supports_no_merge_call():\n\u001B[1;32m---> 51\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstrategy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m distribute_lib\u001B[38;5;241m.\u001B[39mget_replica_context()\u001B[38;5;241m.\u001B[39mmerge_call(\n\u001B[0;32m     54\u001B[0m       fn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1352\u001B[0m, in \u001B[0;36mOptimizer._distributed_apply_gradients_fn\u001B[1;34m(self, distribution, grads_and_vars, **kwargs)\u001B[0m\n\u001B[0;32m   1349\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_step(grad, var)\n\u001B[0;32m   1351\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m grad, var \u001B[38;5;129;01min\u001B[39;00m grads_and_vars:\n\u001B[1;32m-> 1352\u001B[0m     \u001B[43mdistribution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextended\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1353\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapply_grad_to_update_var\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[0;32m   1354\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1356\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_ema:\n\u001B[0;32m   1357\u001B[0m     _, var_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mgrads_and_vars)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2994\u001B[0m, in \u001B[0;36mStrategyExtendedV2.update\u001B[1;34m(self, var, fn, args, kwargs, group)\u001B[0m\n\u001B[0;32m   2992\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update(var, fn, args, kwargs, group)\n\u001B[0;32m   2993\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2994\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_replica_ctx_update\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2995\u001B[0m \u001B[43m      \u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2873\u001B[0m, in \u001B[0;36mStrategyExtendedV2._replica_ctx_update\u001B[1;34m(self, var, fn, args, kwargs, group)\u001B[0m\n\u001B[0;32m   2870\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmerge_fn\u001B[39m(_, \u001B[38;5;241m*\u001B[39mmerged_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmerged_kwargs):\n\u001B[0;32m   2871\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate(var, fn, merged_args, merged_kwargs, group\u001B[38;5;241m=\u001B[39mgroup)\n\u001B[1;32m-> 2873\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mreplica_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmerge_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmerge_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3465\u001B[0m, in \u001B[0;36mReplicaContextBase.merge_call\u001B[1;34m(self, merge_fn, args, kwargs)\u001B[0m\n\u001B[0;32m   3461\u001B[0m   kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m   3463\u001B[0m merge_fn \u001B[38;5;241m=\u001B[39m autograph\u001B[38;5;241m.\u001B[39mtf_convert(\n\u001B[0;32m   3464\u001B[0m     merge_fn, autograph_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx(), convert_by_default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m-> 3465\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_merge_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmerge_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3472\u001B[0m, in \u001B[0;36mReplicaContextBase._merge_call\u001B[1;34m(self, merge_fn, args, kwargs)\u001B[0m\n\u001B[0;32m   3469\u001B[0m _push_per_thread_mode(  \u001B[38;5;66;03m# thread-local, so not needed with multiple threads\u001B[39;00m\n\u001B[0;32m   3470\u001B[0m     _CrossReplicaThreadMode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_strategy))  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   3471\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3472\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmerge_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_strategy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3473\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   3474\u001B[0m   _pop_per_thread_mode()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    688\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    689\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[1;32m--> 690\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    691\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m    692\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001B[0m, in \u001B[0;36mconverted_call\u001B[1;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[0;32m    374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options)\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39muser_requested \u001B[38;5;129;01mand\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_allowlisted(f):\n\u001B[1;32m--> 377\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001B[39;00m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001B[39;00m\n\u001B[0;32m    381\u001B[0m \u001B[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001B[39;00m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;66;03m# things like builtins.\u001B[39;00m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39minternal_convert_user_code:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[1;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[0;32m    456\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mcall(args, kwargs)\n\u001B[0;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2871\u001B[0m, in \u001B[0;36mStrategyExtendedV2._replica_ctx_update.<locals>.merge_fn\u001B[1;34m(_, *merged_args, **merged_kwargs)\u001B[0m\n\u001B[0;32m   2870\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmerge_fn\u001B[39m(_, \u001B[38;5;241m*\u001B[39mmerged_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmerged_kwargs):\n\u001B[1;32m-> 2871\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmerged_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmerged_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2992\u001B[0m, in \u001B[0;36mStrategyExtendedV2.update\u001B[1;34m(self, var, fn, args, kwargs, group)\u001B[0m\n\u001B[0;32m   2989\u001B[0m   fn \u001B[38;5;241m=\u001B[39m autograph\u001B[38;5;241m.\u001B[39mtf_convert(\n\u001B[0;32m   2990\u001B[0m       fn, autograph_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx(), convert_by_default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   2991\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy()\u001B[38;5;241m.\u001B[39mscope():\n\u001B[1;32m-> 2992\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2993\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2994\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_replica_ctx_update(\n\u001B[0;32m   2995\u001B[0m       var, fn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs, group\u001B[38;5;241m=\u001B[39mgroup)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4062\u001B[0m, in \u001B[0;36m_DefaultDistributionExtended._update\u001B[1;34m(self, var, fn, args, kwargs, group)\u001B[0m\n\u001B[0;32m   4059\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update\u001B[39m(\u001B[38;5;28mself\u001B[39m, var, fn, args, kwargs, group):\n\u001B[0;32m   4060\u001B[0m   \u001B[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001B[39;00m\n\u001B[0;32m   4061\u001B[0m   \u001B[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001B[39;00m\n\u001B[1;32m-> 4062\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_non_slot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4068\u001B[0m, in \u001B[0;36m_DefaultDistributionExtended._update_non_slot\u001B[1;34m(self, colocate_with, fn, args, kwargs, should_group)\u001B[0m\n\u001B[0;32m   4064\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update_non_slot\u001B[39m(\u001B[38;5;28mself\u001B[39m, colocate_with, fn, args, kwargs, should_group):\n\u001B[0;32m   4065\u001B[0m   \u001B[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001B[39;00m\n\u001B[0;32m   4066\u001B[0m   \u001B[38;5;66;03m# once that value is used for something.\u001B[39;00m\n\u001B[0;32m   4067\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m UpdateContext(colocate_with):\n\u001B[1;32m-> 4068\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4069\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m should_group:\n\u001B[0;32m   4070\u001B[0m       \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    688\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    689\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[1;32m--> 690\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    691\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m    692\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001B[0m, in \u001B[0;36mconverted_call\u001B[1;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[0;32m    374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options)\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39muser_requested \u001B[38;5;129;01mand\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_allowlisted(f):\n\u001B[1;32m--> 377\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001B[39;00m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001B[39;00m\n\u001B[0;32m    381\u001B[0m \u001B[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001B[39;00m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;66;03m# things like builtins.\u001B[39;00m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39minternal_convert_user_code:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[1;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[0;32m    456\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mcall(args, kwargs)\n\u001B[0;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1349\u001B[0m, in \u001B[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001B[1;34m(var, grad)\u001B[0m\n\u001B[0;32m   1347\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_step_xla(grad, var, \u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_var_key(var)))\n\u001B[0;32m   1348\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1349\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvar\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:241\u001B[0m, in \u001B[0;36m_BaseOptimizer._update_step\u001B[1;34m(self, gradient, variable)\u001B[0m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_var_key(variable) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_dict:\n\u001B[0;32m    233\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\n\u001B[0;32m    234\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe optimizer cannot recognize variable \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvariable\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    235\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis usually means you are trying to call the optimizer to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    239\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.keras.optimizers.legacy.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    240\u001B[0m     )\n\u001B[1;32m--> 241\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvariable\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\keras\\src\\optimizers\\adam.py:199\u001B[0m, in \u001B[0;36mAdam.update_step\u001B[1;34m(self, gradient, variable)\u001B[0m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;66;03m# Dense gradients.\u001B[39;00m\n\u001B[0;32m    198\u001B[0m     m\u001B[38;5;241m.\u001B[39massign_add((gradient \u001B[38;5;241m-\u001B[39m m) \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta_1))\n\u001B[1;32m--> 199\u001B[0m     v\u001B[38;5;241m.\u001B[39massign_add((\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msquare\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m) \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta_2))\n\u001B[0;32m    200\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mamsgrad:\n\u001B[0;32m    201\u001B[0m         v_hat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_velocity_hats[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_dict[var_key]]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1466\u001B[0m, in \u001B[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001B[1;34m(x, y)\u001B[0m\n\u001B[0;32m   1461\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1462\u001B[0m   \u001B[38;5;66;03m# force_same_dtype=False to preserve existing TF behavior\u001B[39;00m\n\u001B[0;32m   1463\u001B[0m   \u001B[38;5;66;03m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001B[39;00m\n\u001B[0;32m   1464\u001B[0m   \u001B[38;5;66;03m#   r_binary_op_wrapper use different force_same_dtype values.\u001B[39;00m\n\u001B[0;32m   1465\u001B[0m   x, y \u001B[38;5;241m=\u001B[39m maybe_promote_tensors(x, y)\n\u001B[1;32m-> 1466\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1467\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1468\u001B[0m   \u001B[38;5;66;03m# Even if dispatching the op failed, the RHS may be a tensor aware\u001B[39;00m\n\u001B[0;32m   1469\u001B[0m   \u001B[38;5;66;03m# object that can implement the operator with knowledge of itself\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1472\u001B[0m   \u001B[38;5;66;03m# original error from the LHS, because it may be more\u001B[39;00m\n\u001B[0;32m   1473\u001B[0m   \u001B[38;5;66;03m# informative.\u001B[39;00m\n\u001B[0;32m   1474\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mtype\u001B[39m(y), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__r\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m__\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m op_name):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1174\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[0;32m   1175\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1176\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m   1178\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[0;32m   1179\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[0;32m   1180\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:549\u001B[0m, in \u001B[0;36msubtract\u001B[1;34m(x, y, name)\u001B[0m\n\u001B[0;32m    545\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmath.subtract\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msubtract\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    546\u001B[0m \u001B[38;5;129m@dispatch\u001B[39m\u001B[38;5;241m.\u001B[39mregister_binary_elementwise_api\n\u001B[0;32m    547\u001B[0m \u001B[38;5;129m@dispatch\u001B[39m\u001B[38;5;241m.\u001B[39madd_dispatch_support\n\u001B[0;32m    548\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msubtract\u001B[39m(x, y, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m--> 549\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgen_math_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msub\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:12937\u001B[0m, in \u001B[0;36msub\u001B[1;34m(x, y, name)\u001B[0m\n\u001B[0;32m  12935\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# Add nodes to the TensorFlow graph.\u001B[39;00m\n\u001B[0;32m  12936\u001B[0m \u001B[38;5;66;03m# Add nodes to the TensorFlow graph.\u001B[39;00m\n\u001B[1;32m> 12937\u001B[0m _, _, _op, _outputs \u001B[38;5;241m=\u001B[39m \u001B[43m_op_def_library\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply_op_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m  12938\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSub\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m  12939\u001B[0m _result \u001B[38;5;241m=\u001B[39m _outputs[:]\n\u001B[0;32m  12940\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _execute\u001B[38;5;241m.\u001B[39mmust_record_gradient():\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:777\u001B[0m, in \u001B[0;36m_apply_op_helper\u001B[1;34m(op_type_name, name, **keywords)\u001B[0m\n\u001B[0;32m    775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m g\u001B[38;5;241m.\u001B[39mas_default(), ops\u001B[38;5;241m.\u001B[39mname_scope(name) \u001B[38;5;28;01mas\u001B[39;00m scope:\n\u001B[0;32m    776\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m fallback:\n\u001B[1;32m--> 777\u001B[0m     \u001B[43m_ExtractInputsAndAttrs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop_type_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_def\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallowed_list_attr_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    778\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mkeywords\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefault_type_attr_map\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    779\u001B[0m \u001B[43m                           \u001B[49m\u001B[43minput_types\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    780\u001B[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001B[0;32m    781\u001B[0m                            default_type_attr_map, attrs)\n\u001B[0;32m    782\u001B[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:550\u001B[0m, in \u001B[0;36m_ExtractInputsAndAttrs\u001B[1;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001B[0m\n\u001B[0;32m    544\u001B[0m       values \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(\n\u001B[0;32m    545\u001B[0m           values,\n\u001B[0;32m    546\u001B[0m           name\u001B[38;5;241m=\u001B[39minput_arg\u001B[38;5;241m.\u001B[39mname,\n\u001B[0;32m    547\u001B[0m           as_ref\u001B[38;5;241m=\u001B[39minput_arg\u001B[38;5;241m.\u001B[39mis_ref,\n\u001B[0;32m    548\u001B[0m           preferred_dtype\u001B[38;5;241m=\u001B[39mdefault_dtype)\n\u001B[0;32m    549\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 550\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    551\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    552\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_arg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    553\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    554\u001B[0m \u001B[43m        \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_arg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_ref\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    555\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreferred_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_dtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    556\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    557\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001B[0m, in \u001B[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    181\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m Trace(trace_name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrace_kwargs):\n\u001B[0;32m    182\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 183\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1443\u001B[0m, in \u001B[0;36mconvert_to_tensor\u001B[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[0;32m   1441\u001B[0m \u001B[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001B[39;00m\n\u001B[0;32m   1442\u001B[0m preferred_dtype \u001B[38;5;241m=\u001B[39m preferred_dtype \u001B[38;5;129;01mor\u001B[39;00m dtype_hint\n\u001B[1;32m-> 1443\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtensor_conversion_registry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1444\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreferred_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccepted_result_types\u001B[49m\n\u001B[0;32m   1445\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001B[0m, in \u001B[0;36mconvert\u001B[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001B[0m\n\u001B[0;32m    225\u001B[0m       \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    226\u001B[0m           _add_error_prefix(\n\u001B[0;32m    227\u001B[0m               \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConversion function \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconversion_func\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m for type \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    230\u001B[0m               \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mactual = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mret\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mbase_dtype\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    231\u001B[0m               name\u001B[38;5;241m=\u001B[39mname))\n\u001B[0;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 234\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mconversion_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mas_ref\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m:\n\u001B[0;32m    237\u001B[0m   \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:2316\u001B[0m, in \u001B[0;36m_dense_var_to_tensor\u001B[1;34m(var, dtype, name, as_ref)\u001B[0m\n\u001B[0;32m   2315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_dense_var_to_tensor\u001B[39m(var, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, as_ref\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m-> 2316\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mvar\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dense_var_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mas_ref\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1558\u001B[0m, in \u001B[0;36mBaseResourceVariable._dense_var_to_tensor\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m   1556\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread_value()\u001B[38;5;241m.\u001B[39mop\u001B[38;5;241m.\u001B[39minputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1558\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:633\u001B[0m, in \u001B[0;36mBaseResourceVariable.value\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    631\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cached_value\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28;01mNone\u001B[39;00m, ignore_existing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m--> 633\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_variable_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:794\u001B[0m, in \u001B[0;36mBaseResourceVariable._read_variable_op\u001B[1;34m(self, no_copy)\u001B[0m\n\u001B[0;32m    792\u001B[0m       result \u001B[38;5;241m=\u001B[39m read_and_set_handle(no_copy)\n\u001B[0;32m    793\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 794\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[43mread_and_set_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mno_copy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    796\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m    797\u001B[0m   \u001B[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001B[39;00m\n\u001B[0;32m    798\u001B[0m   \u001B[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001B[39;00m\n\u001B[0;32m    799\u001B[0m   record\u001B[38;5;241m.\u001B[39mrecord_operation(\n\u001B[0;32m    800\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReadVariableOp\u001B[39m\u001B[38;5;124m\"\u001B[39m, [result], [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle],\n\u001B[0;32m    801\u001B[0m       backward_function\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: [x],\n\u001B[0;32m    802\u001B[0m       forward_function\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: [x])\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:784\u001B[0m, in \u001B[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001B[1;34m(no_copy)\u001B[0m\n\u001B[0;32m    782\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m no_copy \u001B[38;5;129;01mand\u001B[39;00m forward_compat\u001B[38;5;241m.\u001B[39mforward_compatible(\u001B[38;5;241m2022\u001B[39m, \u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m3\u001B[39m):\n\u001B[0;32m    783\u001B[0m   gen_resource_variable_ops\u001B[38;5;241m.\u001B[39mdisable_copy_on_read(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle)\n\u001B[1;32m--> 784\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mgen_resource_variable_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_variable_op\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    785\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    786\u001B[0m _maybe_set_handle_data(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dtype, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle, result)\n\u001B[0;32m    787\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:595\u001B[0m, in \u001B[0;36mread_variable_op\u001B[1;34m(resource, dtype, name)\u001B[0m\n\u001B[0;32m    593\u001B[0m \u001B[38;5;66;03m# Add nodes to the TensorFlow graph.\u001B[39;00m\n\u001B[0;32m    594\u001B[0m dtype \u001B[38;5;241m=\u001B[39m _execute\u001B[38;5;241m.\u001B[39mmake_type(dtype, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 595\u001B[0m _, _, _op, _outputs \u001B[38;5;241m=\u001B[39m \u001B[43m_op_def_library\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply_op_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    596\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mReadVariableOp\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresource\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    597\u001B[0m _result \u001B[38;5;241m=\u001B[39m _outputs[:]\n\u001B[0;32m    598\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _execute\u001B[38;5;241m.\u001B[39mmust_record_gradient():\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:777\u001B[0m, in \u001B[0;36m_apply_op_helper\u001B[1;34m(op_type_name, name, **keywords)\u001B[0m\n\u001B[0;32m    775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m g\u001B[38;5;241m.\u001B[39mas_default(), ops\u001B[38;5;241m.\u001B[39mname_scope(name) \u001B[38;5;28;01mas\u001B[39;00m scope:\n\u001B[0;32m    776\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m fallback:\n\u001B[1;32m--> 777\u001B[0m     \u001B[43m_ExtractInputsAndAttrs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop_type_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_def\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallowed_list_attr_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    778\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mkeywords\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefault_type_attr_map\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    779\u001B[0m \u001B[43m                           \u001B[49m\u001B[43minput_types\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    780\u001B[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001B[0;32m    781\u001B[0m                            default_type_attr_map, attrs)\n\u001B[0;32m    782\u001B[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GenerativeDL\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:416\u001B[0m, in \u001B[0;36m_ExtractInputsAndAttrs\u001B[1;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001B[0m\n\u001B[0;32m    414\u001B[0m inferred_from \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    415\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m input_arg \u001B[38;5;129;01min\u001B[39;00m op_def\u001B[38;5;241m.\u001B[39minput_arg:\n\u001B[1;32m--> 416\u001B[0m   input_name \u001B[38;5;241m=\u001B[39m \u001B[43minput_arg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\n\u001B[0;32m    417\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m input_name \u001B[38;5;129;01min\u001B[39;00m keywords:\n\u001B[0;32m    418\u001B[0m     values \u001B[38;5;241m=\u001B[39m keywords\u001B[38;5;241m.\u001B[39mpop(input_name)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "dcgan.fit(\n",
    "    train,\n",
    "    epochs = EPOCHS,\n",
    "    initial_epoch = 1,\n",
    "    callbacks = [\n",
    "        model_checkpoint_callback,\n",
    "        tensorboard_callback,\n",
    "        ImageGenerator(num_img = 10, latent_dim = Z_DIM)\n",
    "    ],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T15:24:41.852142700Z",
     "start_time": "2024-02-29T15:23:20.011109500Z"
    }
   },
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save the final models\n",
    "generator.save(\"./models/generator\")\n",
    "discriminator.save(\"./models/discriminator\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-29T14:15:56.000774700Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate New Images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Sample some points in the latent space, from the standard normal distribution\n",
    "grid_width, grid_height = (10, 3)\n",
    "z_sample = np.random.normal(size=(grid_width * grid_height, Z_DIM))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Decode the sampled points\n",
    "reconstructions = generator.predict(z_sample)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Draw a plot of decoded images\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "# Output the grid of faces\n",
    "for i in range(grid_width * grid_height):\n",
    "    ax = fig.add_subplot(grid_height, grid_width, i + 1)\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(reconstructions[i, :, :], cmap=\"Greys\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# My Takeaways\n",
    "\n",
    "The discriminator can overpower the generator. If this happens it means the discriminator has overfit the training data. 'Overpower' means being able to discern the real from the fake with 100% accuracy. It also means that the generator can't learn from the discriminator when it's like that as it needs to know how to improve in generating images that look real. If the discriminator effectively says \"You can't fool me - I know all your images are fake.\", the generator has no feedback.\n",
    "\n",
    "To prevent this from happening and to create smoother decision boundaries, I can:\n",
    "\n",
    "- Increase the dropout rate - effectively telling the model to dampen the amount of information that flows through the network. Increasing the dropout rate means that the model won't know everything there is to know about the real images it is being trained on, which means it won't be able to learn how to discern with 100% certainty (just eventually very close to - meaning there'll always be feedback given to the generator for it to improve). The goal is always to improve the generator to a point where its images look near identical to the real.\n",
    "\n",
    "- I can reduce the learning rate - so it takes longer for the discriminator to reach the highest level of discernment. This gives the generator more time to improve as it'll receive more feedback.\n",
    "\n",
    "- I can reduce the number of convolutional filters in the discriminator - this just means that the discriminator is inspecting the real and fake images at reduced granularity. Reduced granularity means that it is less likely to overfit to the training data as it knows less about the real images. Knowing less about the real images makes it easier for the generator to produce fake images that are harder to distinguish from the real. Again, there'll always be feedback for the generator. This can have the unintended effect of capping the generator's learning capacity as it will receive less complex/detailed feedback on how to improve. It'll reach a certain point where it'll produce real-ish images but can't improve anymore without better feedback (which the discriminator won't be able to provide because it can't inspect the real images at the level of granularity required). \n",
    "\n",
    "- I can add noise to the labels when training the discriminator - adding noise to the prevents the discriminator from becoming too confident and overfitting to the data. Noise in the labels can disrupt the discriminator's learning process, forcing it to learn more robust features and decision boundaries. This can lead to more stable training dynamics and faster convergence of the GAN. The crucial part is that the noise has to be random and varying. I'm effectively adding small and varying amounts of loss to the model - encouraging the discriminator to dig deeper and wider in finding features in the dataset.  \n",
    "\n",
    "- I could flip the labels of some images at random when training the discriminator. This seems heavy-handed as it has the potential of confusing or more likely slowing down convergence. However, if done on a very small scale it also forces the discriminator to dig deeper and wider when learning new features. \n",
    "\n",
    "If the discriminator is not powerful enough, it can lead to mode collapse. 'Mode collapse' occurs when the generator has learnt as much as it can know from the discriminator and is able to trick it into thinking all the images it produces are real but not enough for it to produce images to the same range and quality as the real dataset. It'll be able to produce all the ones that are less detailed but have no way to improve to be able to produce the most detailed. This follows from the above - a discriminator with reduced capacity caps the generator's abilities which can lead to mode collapse - stasis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wasserstein GAN with Gradient Penalty (WGAN-GP) (improved model)\n",
    "\n",
    "- Uses the Wasserstein loss function for both the discriminator and the generator. Using this loss function instead of binary cross-entropy results in a more stable convergence of the GAN. \n",
    "- First, the Wasserstein loss requires that we use 1 and 1 as labels (real or fake), rather than 1 and 0. We also remove the sigmoid activation from the final layer of the discriminator, so that predictions are no longer constrained to fall in the range [0, 1] but instead can now be any number in the range [-infinity, infinity]. For this reason, the discriminator in a WGAN is usually referred to as a **critic** that outputs a score rather than a probability. This loss function encourages the critic (discriminator) network to produce output scores that correspond to the **quality** of the generated samples and the real data distribution.\n",
    "- Wasserstein distance is a more meaningful metric for comparing probability distributions. It measures the minimum amount of work needed to transform one distribution into another, which can be advantageous when dealing with complex data distributions.\n",
    "- The WGAN generator tries to produce images that are scored as highly as possible by the critic (i.e., the critic is fooled into thinking they are real).\n",
    "- With predictions no longer being constrained to the [0, 1] range resulting in very large numbers, a constraint is required. \n",
    "- In WGAN-GP, the gradient penalty term is added to the loss function to enforce the Lipschitz constraint on the critic (discriminator) network. This term penalizes the critic if its gradients deviate significantly from a target value, typically 1.0, helping to ensure smoother training dynamics and better convergence.\n",
    "- A key addition is the gradient penalty loss included as part of the overall loss function, alongside the Wasserstein loss from the real and fake images.\n",
    "- The interpolation path is a technique used specifically for evaluating the gradient penalty term. It involves generating interpolated images along straight lines between pairs of real and fake images and computing the gradients of the critic's output with respect to these interpolated images. By enforcing smoothness along these paths, the gradient penalty term helps stabilize training and ensures the critic adheres to the Lipschitz constraint.\n",
    "- By providing more meaningful gradients to both the generator and discriminator, Wasserstein loss encourages the model to capture the entire data distribution more effectively."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training the WGAN-GP\n",
    "\n",
    "- No balancing between critic and generator is required - the critic can be trained a lot more - this is a key benefit. When using the Wasserstein loss, the critic must be trained to convergence before updating the generator, to ensure that the gradients for the generator update are accurate. This is in contrast to a standard GAN, where it is important not to let the discriminator get too strong.\n",
    "\n",
    "- Therefore, with Wasserstein GANs, we can simply train the critic several times between generator updates, to ensure it is close to convergence. A typical ratio used is three to five critic updates per generator update.\n",
    "- In theory, allowing the critic (discriminator) to be trained more effectively in WGAN-GP compared to a regular GAN can potentially lead to better identification of detailed features in the input dataset. However, it's important to note that the effectiveness of WGAN-GP depends on various factors, including the dataset, network architecture, and training parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### The gradient penalty loss function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def gradient_penalty(self, batch_size, rela_images, fake_images):\n",
    "    # 1. Each image in the batch gets a random number, between\n",
    "    #    0 and 1, stored as the vector alpha.\n",
    "    alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "    diff = fake_images - real_images\n",
    "    \n",
    "    # 2. A set of interpolated images is calculated.\n",
    "    interpolated = real_images + alpha * diff\n",
    "    \n",
    "    # 3. The current critic is asked to score each of these\n",
    "    #    interpolated images.\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        pred = self.critic(interpolated, training=True)\n",
    "    \n",
    "    # 4. The gradient of the predictions is calculated with\n",
    "    #    respect to the input images.\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "    \n",
    "    # 5. The L2 norm of this vector is calculated.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.sqaure(grads), axis=[1, 2, 3]))\n",
    "    \n",
    "    # 6. The function returns the average squared distance between the L2 norm and 1.\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return gp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T02:58:25.168137900Z",
     "start_time": "2024-03-20T02:58:25.145420100Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
